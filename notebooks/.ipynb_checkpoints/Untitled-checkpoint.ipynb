{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "Parent module '' not loaded, cannot perform relative import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d6cdbd126fe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m: Parent module '' not loaded, cannot perform relative import"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image as Img\n",
    "from keras.layers import Input, Dense, TimeDistributed, LSTM, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Conv2D, BatchNormalization, Lambda\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras import backend\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7d8e37a8c2fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/debug/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_val_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dir = \"data/debug/\"\n",
    "ds = load_dataset(dir)\n",
    "x_train, y_train = ds.get_train_full()\n",
    "x_val, y_val = ds.get_val_full()\n",
    "# print(len(x))\n",
    "# print(len(y))\n",
    "# print(x[1], x[1].shape)\n",
    "# print(y[1], y[1].shape)\n",
    "\n",
    "#print(X_train.shape())\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 12\n",
    "#n_features = x[0].shape[2]\n",
    "#n_time = x[0].shape[1]\n",
    "\n",
    "N_LAYERS = 3\n",
    "FILTER_LENGTH = 5\n",
    "CONV_FILTER_COUNT = 56\n",
    "BATCH_SIZE = 32\n",
    "LSTM_COUNT = 96\n",
    "EPOCH_COUNT = 70\n",
    "NUM_HIDDEN = 64\n",
    "L2_regularization = 0.001\n",
    "\n",
    "# num = 1\n",
    "# spectogram = x[num]\n",
    "# #genre = np.argmax(y_train[num])\n",
    "# #print(reverse_map[genre])\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.pcolormesh(spectogram)\n",
    "# #librosa.display.specshow(spectogram.T, y_axis='mel', x_axis='time')\n",
    "# plt.colorbar(format='%+2.0f dB')\n",
    "# plt.title('Test Melspectogram')\n",
    "# plt.show()\n",
    "# #plt.tight_layout()\n",
    "\n",
    "def conv_recurrent_model_build(model_input):\n",
    "    print('Building model...')\n",
    "    layer = model_input\n",
    "\n",
    "    ### 3 1D Convolution Layers\n",
    "    for i in range(N_LAYERS):\n",
    "        # give name to the layers\n",
    "        layer = Conv1D(\n",
    "            filters=CONV_FILTER_COUNT,\n",
    "            kernel_size=FILTER_LENGTH,\n",
    "            kernel_regularizer=regularizers.l2(L2_regularization),  # Tried 0.001\n",
    "            name='convolution_' + str(i + 1)\n",
    "        )(layer)\n",
    "        layer = BatchNormalization(momentum=0.9)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = MaxPooling1D(2)(layer)\n",
    "        layer = Dropout(0.4)(layer)\n",
    "\n",
    "    ## LSTM Layer\n",
    "    layer = LSTM(LSTM_COUNT, return_sequences=False)(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "\n",
    "    ## Dense Layer\n",
    "    layer = Dense(NUM_HIDDEN, kernel_regularizer=regularizers.l2(L2_regularization), name='dense1')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "\n",
    "    ## Softmax Output\n",
    "    layer = Dense(num_classes)(layer)\n",
    "    layer = Activation('softmax', name='output_realtime')(layer)\n",
    "    model_output = layer\n",
    "    model = Model(model_input, model_output)\n",
    "\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(x_train, y_train, x_val, y_val):\n",
    "    print(x_train.shape)\n",
    "    n_features = x_train[0].shape[0]\n",
    "    input_shape = (n_features,256)\n",
    "    model_input = Input(input_shape, name='input')\n",
    "\n",
    "    model = conv_recurrent_model_build(model_input)\n",
    "\n",
    "    #     tb_callback = TensorBoard(log_dir='./logs/4', histogram_freq=1, batch_size=32, write_graph=True, write_grads=False,\n",
    "    #                               write_images=False, embeddings_freq=0, embeddings_layer_names=None,\n",
    "    #                               embeddings_metadata=None)\n",
    "    #checkpoint_callback = ModelCheckpoint('../models/crnn/weights.best.h5', monitor='val_acc', verbose=1,\n",
    "                                          #save_best_only=True, mode='max')\n",
    "\n",
    "    reducelr_callback = ReduceLROnPlateau(\n",
    "        monitor='val_acc', factor=0.5, patience=10, min_delta=0.01,\n",
    "        verbose=1\n",
    "    )\n",
    "    #callbacks_list = [checkpoint_callback, reducelr_callback]\n",
    "\n",
    "    # Fit the model and get training history.\n",
    "    print('Training...')\n",
    "    plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
    "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT,\n",
    "                        validation_data=(x_val, y_val), verbose=1)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "model, history  = train_model(np.array(x_train), np.array(y_train), np.array(x_val), np.array(y_val))\n",
    "#plot_model(model, show_shapes=True,show_layer_names=True,to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
