{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "__author__ = \"Sri Datta Budaraju\"\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def convert_to_tfRecords(data_path, info_path, dataset, tfRecord_name):\n",
    "    \"\"\"\n",
    "    Convert each sample.npz to tf record along with the label\n",
    "    \n",
    "    Arguments:\n",
    "        data_path -- path to .npz files\n",
    "        info_path -- path to json file\n",
    "        dataset -- train/val/test according to the json keys\n",
    "        tfRecord_name -- name the tfRecord\n",
    "        \n",
    "    outputs:\n",
    "        writes tfRecords\n",
    "    \"\"\"\n",
    "    \n",
    "    # Helper functions to Format features\n",
    "    def _float_feature(value):\n",
    "        \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "    def _int64_feature(value):\n",
    "        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "    \n",
    "    # Progress bar\n",
    "    totalfiles = 0\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.npz'):\n",
    "                totalfiles += 1\n",
    "    \n",
    "    pbar = tqdm(total=totalfiles)\n",
    "\n",
    "    # get ground truth info\n",
    "    with open(\"../data/debug/info.json\") as json_file:\n",
    "        info = json.load(json_file)\n",
    "    label_list = info[dataset]['composer-label']\n",
    "    counter = 0\n",
    "    \n",
    "    # tfRecord Writer\n",
    "    if(os.path.isfile(tfRecord_name+\".tfrecords\")):\n",
    "        print(\"Record with the same name exists\")\n",
    "        return \n",
    "    writer = tf.python_io.TFRecordWriter(tfRecord_name +\n",
    "                                         '.tfrecords')\n",
    "\n",
    "    # for each spectrogram\n",
    "    for sample in sorted(os.listdir(data_path),\n",
    "                         key=lambda x: int(re.split(r'(\\d+)', x)[1])):\n",
    "        sample = np.load(data_path + sample)\n",
    "        sample_lmfcc = sample[\"arr_0\"]\n",
    "\n",
    "        # Features 1D spectrogram and composer-label\n",
    "        feature = {\n",
    "            'feature0': _float_feature(sample['arr_0'].flatten(order='F')),\n",
    "            'feature1': _int64_feature(label_list[counter])\n",
    "        }\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        serialized = example.SerializeToString()\n",
    "        # Write serialized record\n",
    "        writer.write(serialized)\n",
    "        \n",
    "        counter += 1\n",
    "        pbar.update(1)\n",
    "        pbar.refresh()\n",
    "    \n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924b434218794ffd97d89db440554a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=116), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the function\n",
    "\n",
    "data_path = \"../data/debug/test/\"\n",
    "info_path = \"../data/debug/info.json\"\n",
    "dataset = \"test\"\n",
    "tfRecord_name = \"../data/debug/sample\"\n",
    "\n",
    "convert_to_tfRecords(data_path, info_path, dataset, tfRecord_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 256) --> 0\n"
     ]
    }
   ],
   "source": [
    "# Reading from records\n",
    "\n",
    "for record in tf.python_io.tf_record_iterator(tfRecord_name+'.tfrecords'):\n",
    "    example = tf.train.Example()\n",
    "    _ = example.ParseFromString(record)\n",
    "    LMFCC = np.array(example.features.feature['feature0'].float_list.value)\n",
    "    LMFCC = LMFCC.reshape(128, 256, order=\"F\")\n",
    "    label = np.array(example.features.feature['feature1'].int64_list.value)\n",
    "    print(LMFCC.shape, end=' --> ')\n",
    "    print(*label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 256)\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "\n",
    "sample = np.load(\"../data/debug/test/sample0.npz\")\n",
    "sample = sample[\"arr_0\"]\n",
    "print(sample.shape)\n",
    "assert(np.allclose([sample], LMFCC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
